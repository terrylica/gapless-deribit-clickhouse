# ADR: 2025-12-08-clickhouse-naming-convention
min_version = "2024.9.5"

[env]
# Automatic venv activation - mise will use uv to create it
_.python.venv = { path = ".venv", create = true }
# Load ClickHouse credentials from .env (SSoT)
_.file = '.env'

# Schema-first configuration (SSoT)
CLICKHOUSE_DATABASE = "deribit"
CLICKHOUSE_TABLE = "options_trades"

# ClickHouse Cloud Region (for AWS resource deployment)
# ADR: 2025-12-08-clickhouse-data-pipeline-architecture
CLICKHOUSE_CLOUD_REGION = "us-west-2"
AWS_DEFAULT_REGION = "us-west-2"

# Dual-mode: "local" for development/backtesting, "cloud" for production
CLICKHOUSE_MODE = "cloud"

# Local ClickHouse (when CLICKHOUSE_MODE=local)
# Note: clickhouse-connect uses HTTP interface (port 8123, not native 9000)
CLICKHOUSE_LOCAL_HOST = "localhost"
CLICKHOUSE_LOCAL_PORT = "8123"

# ClickHouse Server Configuration (local development)
# ADR: 2025-12-08-mise-pagination-validation
CLICKHOUSE_DATA_DIR = "{{config_root}}/tmp/clickhouse/data"
CLICKHOUSE_LOG_DIR = "{{config_root}}/tmp/clickhouse/logs"
CLICKHOUSE_PID_FILE = "{{config_root}}/tmp/clickhouse/clickhouse.pid"

# Pagination Validation Settings
PAGINATION_GAP_THRESHOLD_MS = "1000"
PAGINATION_LOG_WARNINGS = "true"

[tools]
# Flexible Python: accept any 3.11+ (matches pyproject.toml requires-python)
python = "3"
uv = "latest"
clickhouse = "latest"  # Replaces Homebrew - version-managed
node = "latest"        # For semantic-release

[tasks.install]
description = "Install dependencies with uv"
alias = "i"
run = "uv sync --all-extras"

[tasks.venv-recreate]
description = "Recreate virtual environment from scratch"
run = """
rm -rf .venv
uv venv .venv
uv sync --all-extras
"""

[tasks.test]
description = "Run all tests"
run = "uv run pytest tests/ -v"

[tasks.test-unit]
description = "Run unit tests only (no credentials)"
depends = ["lint"]
run = "uv run pytest tests/ -v -m 'not slow and not e2e'"

# =============================================================================
# E2E Validation Flow (Proper Dependency Chain)
# =============================================================================
# The validation flow ensures prerequisites are met before running tests:
#
#   _check-source → _check-data-exists → test-e2e
#                          ↓ (if empty)
#                    seed-sample-data
#
# This prevents the "empty database" test failure scenario.

[tasks._check-source]
description = "Verify Deribit API source is reachable"
hide = true
run = """
curl -sf "https://history.deribit.com/api/v2/public/get_last_trades_by_currency_and_time?currency=BTC&kind=option&count=1&start_timestamp=0&end_timestamp=1704067200000" > /dev/null && \
  echo "✓ Deribit API reachable" || \
  { echo "❌ Deribit API unreachable"; exit 1; }
"""

[tasks._check-data-exists]
description = "Verify ClickHouse has sufficient data for E2E tests"
hide = true
depends = ["_check-credentials"]
run = """
uv run python -c "
from gapless_deribit_clickhouse.clickhouse.connection import get_client
client = get_client()
count = client.command('SELECT count() FROM deribit.options_trades')
if count < 100:
    print(f'❌ Insufficient data: {count} rows (need >= 100)')
    print('   Run: mise run seed-sample-data')
    exit(1)
print(f'✓ ClickHouse has {count:,} rows')
"
"""

# ADR: 2025-12-10-schema-optimization - Consolidated seeding task
# Replaces: seed-sample-data, seed-local, seed-cloud (7 tasks → 1 mode-aware task)
[tasks.seed]
description = "Seed ClickHouse with 1 day of real Deribit data (mode-aware)"
depends = ["_check-source"]
run = """
uv run python -c "
from gapless_deribit_clickhouse import collect_trades
from gapless_deribit_clickhouse.clickhouse.connection import get_client
import os
import logging
logging.basicConfig(level=logging.INFO)

mode = os.environ.get('CLICKHOUSE_MODE', 'cloud')
print(f'Seeding {mode.upper()} ClickHouse with 1 day of BTC options trades...')

# Verify connection first
try:
    client = get_client()
    client.command('SELECT 1')
except Exception as e:
    print(f'❌ Cannot connect to {mode} ClickHouse: {e}')
    exit(1)

df = collect_trades(
    currency='BTC',
    start_date='2024-12-01',
    end_date='2024-12-02',
    insert_to_db=True,
    resume=False
)
print(f'✓ Seeded {len(df):,} trades to {mode} ClickHouse')
"
"""

[tasks.test-e2e]
description = "Run E2E tests (requires credentials + data)"
depends = ["_check-source", "_check-data-exists"]
run = "uv run pytest tests/e2e/ -v -m e2e"

[tasks.test-contracts]
description = "Run contract tests"
run = "uv run pytest tests/contracts/ -v"

[tasks.lint]
description = "Run ruff linting"
run = "uv run ruff check src/"

[tasks.format]
description = "Format code"
run = "uv run ruff format src/ tests/"

[tasks.schema-validate]
description = "Validate YAML schema vs live ClickHouse"
run = "uv run python -m gapless_deribit_clickhouse.schema.cli validate"

[tasks.schema-diff]
description = "Show schema drift between YAML and live"
run = "uv run python -m gapless_deribit_clickhouse.schema.cli diff"

[tasks.security]
description = "Run security scans (semgrep + gitleaks)"
run = """
semgrep scan --config auto src/ && gitleaks detect --source .
"""

[tasks.ci]
description = "Full CI pipeline (lint + tests + security)"
depends = ["lint", "test-unit", "test-contracts", "security"]
run = "echo '✓ CI pipeline passed'"

# Hidden helper tasks (internal utilities)
# ADR: 2025-12-08-clickhouse-naming-convention

[tasks._check-credentials]
description = "Verify ClickHouse credentials are set"
hide = true
run = """
if [ -z "$CLICKHOUSE_HOST_READONLY" ]; then
  echo "❌ CLICKHOUSE_HOST_READONLY not set. Copy .env.example to .env"
  exit 1
fi
echo "✓ Credentials configured"
"""

[tasks._confirm-destructive]
description = "Confirm destructive operation"
hide = true
run = """
echo "⚠️  This will DROP existing data. Press Enter to continue or Ctrl+C to cancel..."
read
"""

# Database management tasks with depends_post for automatic validation

[tasks.db-init]
description = "Create ClickHouse database and table from schema"
depends = ["_check-credentials"]
depends_post = ["schema-validate"]
run = "uv run python -m gapless_deribit_clickhouse.schema.cli init"

[tasks.db-drop]
description = "Drop legacy database (destructive!)"
depends = ["_check-credentials", "_confirm-destructive"]
run = "uv run python -m gapless_deribit_clickhouse.schema.cli drop-legacy"

[tasks.db-migrate]
description = "Full migration: drop legacy + create new + validate"
depends = ["db-drop", "db-init"]
# ADR: 2025-12-10-schema-optimization - use consolidated seed task
depends_post = ["seed", "test-e2e"]
run = "echo '✓ Migration complete'"

# =============================================================================
# Dual-Mode Orchestration Tasks
# ADR: 2025-12-08-clickhouse-data-pipeline-architecture
# =============================================================================

[tasks._check-local-server]
description = "Verify local ClickHouse is running"
hide = true
run = """
curl -s http://localhost:8123/ping > /dev/null 2>&1 || {
  echo "❌ Local ClickHouse not running. Start with: clickhouse server"
  exit 1
}
echo "✓ Local ClickHouse running"
"""

[tasks.local-init]
description = "Initialize local ClickHouse with same schema as cloud"
env = { CLICKHOUSE_MODE = "local" }
depends = ["_check-local-server"]
depends_post = ["local-validate"]
run = "uv run python -m gapless_deribit_clickhouse.schema.cli init"

[tasks.local-validate]
description = "Validate local schema matches YAML"
env = { CLICKHOUSE_MODE = "local" }
run = "uv run python -m gapless_deribit_clickhouse.schema.cli validate"

[tasks.cloud-validate]
description = "Validate cloud schema matches YAML"
env = { CLICKHOUSE_MODE = "cloud" }
depends = ["_check-credentials"]
run = "uv run python -m gapless_deribit_clickhouse.schema.cli validate"

[tasks.schema-align]
description = "Verify local and cloud schemas are aligned"
depends = ["local-validate", "cloud-validate"]
run = "echo '✓ Local and cloud schemas aligned with YAML SSoT'"

[tasks.e2e-validate]
description = "E2E validation: collect real Deribit data to local ClickHouse"
env = { CLICKHOUSE_MODE = "local" }
depends = ["local-init", "_check-local-server", "_check-source"]
run = """
uv run python -c "
from gapless_deribit_clickhouse import collect_trades
from gapless_deribit_clickhouse.clickhouse.connection import get_client
import os

os.environ['CLICKHOUSE_MODE'] = 'local'

print('Step 1: Collecting real data from Deribit API (1 hour window)...')
df = collect_trades(
    currency='BTC',
    start_date='2024-12-01',
    end_date='2024-12-01 01:00:00',
    insert_to_db=True
)
print(f'Collected and inserted {len(df)} real trades')

print('Step 2: Verifying inserted data...')
client = get_client(mode='local')
count = client.command('SELECT count() FROM deribit.options_trades')
assert count > 0, f'Expected trades, got {count}'
print(f'Local ClickHouse has {count} rows')

print('E2E validation PASSED')
"
"""

[tasks._check-cloud-data]
description = "Verify Cloud ClickHouse has data"
hide = true
env = { CLICKHOUSE_MODE = "cloud" }
depends = ["_check-credentials"]
run = """
uv run python -c "
from gapless_deribit_clickhouse.clickhouse.connection import get_client
client = get_client()
count = client.command('SELECT count() FROM deribit.options_trades')
if count < 100:
    print(f'❌ Cloud: insufficient data ({count} rows)')
    exit(1)
print(f'✓ Cloud ClickHouse: {count:,} rows')
"
"""

[tasks._check-local-data]
description = "Verify Local ClickHouse has data"
hide = true
env = { CLICKHOUSE_MODE = "local" }
depends = ["_check-local-server"]
run = """
uv run python -c "
from gapless_deribit_clickhouse.clickhouse.connection import get_client
client = get_client()
count = client.command('SELECT count() FROM deribit.options_trades')
if count < 100:
    print(f'⚠️  Local: insufficient data ({count} rows)')
    print('   Run: mise run seed-local')
    exit(1)
print(f'✓ Local ClickHouse: {count:,} rows')
"
"""

# ADR: 2025-12-10 - Auto-seed helper tasks for consistent seeding patterns
[tasks._ensure-local-data]
description = "Ensure Local ClickHouse has data (auto-seeds if empty)"
hide = true
env = { CLICKHOUSE_MODE = "local" }
depends = ["_check-local-server", "local-init"]
run = """
uv run python -c "
from gapless_deribit_clickhouse.clickhouse.connection import get_client
from gapless_deribit_clickhouse import collect_trades
import logging
logging.basicConfig(level=logging.INFO)

client = get_client()
count = client.command('SELECT count() FROM deribit.options_trades')
print(f'Current data: {count:,} rows')

if count < 100:
    print('Insufficient data - auto-seeding with 1 day of trades...')
    df = collect_trades(
        currency='BTC',
        start_date='2024-12-01',
        end_date='2024-12-02',
        insert_to_db=True,
        resume=False
    )
    print(f'✓ Auto-seeded {len(df):,} trades')
else:
    print('✓ Sufficient data exists')
"
"""

[tasks._ensure-cloud-data]
description = "Ensure Cloud ClickHouse has data (auto-seeds if empty)"
hide = true
env = { CLICKHOUSE_MODE = "cloud" }
depends = ["_check-credentials"]
run = """
uv run python -c "
from gapless_deribit_clickhouse.clickhouse.connection import get_client
from gapless_deribit_clickhouse import collect_trades
import logging
logging.basicConfig(level=logging.INFO)

client = get_client()
count = client.command('SELECT count() FROM deribit.options_trades')
print(f'Current data: {count:,} rows')

if count < 100:
    print('Insufficient data - auto-seeding with 1 day of trades...')
    df = collect_trades(
        currency='BTC',
        start_date='2024-12-01',
        end_date='2024-12-02',
        insert_to_db=True,
        resume=False
    )
    print(f'✓ Auto-seeded {len(df):,} trades')
else:
    print('✓ Sufficient data exists')
"
"""

# ADR: 2025-12-10-schema-optimization - Mode-specific aliases for seed task
[tasks.seed-local]
description = "Seed Local ClickHouse (alias for: CLICKHOUSE_MODE=local mise run seed)"
env = { CLICKHOUSE_MODE = "local" }
depends = ["_check-local-server", "local-init", "seed"]
run = "echo '✓ Local seeding complete'"

[tasks.seed-cloud]
description = "Seed Cloud ClickHouse (alias for: CLICKHOUSE_MODE=cloud mise run seed)"
env = { CLICKHOUSE_MODE = "cloud" }
depends = ["_check-credentials", "seed"]
run = "echo '✓ Cloud seeding complete'"

[tasks.test-e2e-local]
description = "Run E2E tests against Local ClickHouse (auto-seeds if empty)"
env = { CLICKHOUSE_MODE = "local" }
# ADR: 2025-12-10 - Use _ensure-* for consistent auto-seeding behavior
depends = ["_check-source", "_ensure-local-data"]
run = "uv run pytest tests/e2e/ -v -m e2e"

[tasks.test-e2e-cloud]
description = "Run E2E tests against Cloud ClickHouse (auto-seeds if empty)"
env = { CLICKHOUSE_MODE = "cloud" }
# ADR: 2025-12-10 - Use _ensure-* for consistent auto-seeding behavior
depends = ["_check-source", "_ensure-cloud-data"]
run = "uv run pytest tests/e2e/ -v -m e2e"

[tasks.validate-local]
description = "Full validation of Local ClickHouse"
env = { CLICKHOUSE_MODE = "local" }
# ADR: 2025-12-10 - dbeaver-generate BEFORE validate (fresh clones need config generated)
depends = ["_check-source", "_check-local-server", "local-validate", "_check-local-data", "dbeaver-generate", "dbeaver-validate", "test-e2e-local"]
run = """
echo ""
echo "═══════════════════════════════════════════════════════════"
echo "  ✓ Local Validation Passed"
echo "═══════════════════════════════════════════════════════════"
echo "  • Deribit API: reachable"
echo "  • Local ClickHouse: running"
echo "  • Schema: YAML matches local database"
echo "  • DBeaver config: Pydantic validated"
echo "  • Data: sufficient rows"
echo "  • E2E tests: passed"
echo "═══════════════════════════════════════════════════════════"
"""

[tasks.validate-cloud]
description = "Full validation of Cloud ClickHouse"
env = { CLICKHOUSE_MODE = "cloud" }
# ADR: 2025-12-10 - dbeaver-generate BEFORE validate (fresh clones need config generated)
depends = ["_check-source", "_check-credentials", "cloud-validate", "_check-cloud-data", "dbeaver-generate", "dbeaver-validate", "test-e2e-cloud"]
run = """
echo ""
echo "═══════════════════════════════════════════════════════════"
echo "  ✓ Cloud Validation Passed"
echo "═══════════════════════════════════════════════════════════"
echo "  • Deribit API: reachable"
echo "  • Cloud credentials: configured"
echo "  • Schema: YAML matches cloud database"
echo "  • DBeaver config: Pydantic validated"
echo "  • Data: sufficient rows"
echo "  • E2E tests: passed"
echo "═══════════════════════════════════════════════════════════"
"""

[tasks.validate-full]
description = "Full validation: Local + Cloud (both environments)"
# ADR: 2025-12-09-pydantic-dbeaver-config
# Skill: clickhouse-pydantic-config (cc-skills)
depends = ["_check-source", "dbeaver-generate", "dbeaver-validate", "validate-local", "validate-cloud"]
run = """
echo ""
echo "═══════════════════════════════════════════════════════════"
echo "  ✓ FULL DUAL-MODE VALIDATION PASSED"
echo "═══════════════════════════════════════════════════════════"
echo "  • Deribit API: reachable"
echo "  • Pydantic SSoT: DBeaver config validated"
echo "  • Local ClickHouse: schema ✓ | data ✓ | E2E ✓"
echo "  • Cloud ClickHouse: schema ✓ | data ✓ | E2E ✓"
echo "═══════════════════════════════════════════════════════════"
"""

# ADR: 2025-12-10-schema-optimization - Simplified, no circular depends_post
[tasks.validate-and-seed]
description = "Validate schema and auto-seed if database is empty"
depends = ["_check-source", "_check-credentials", "schema-validate"]
run = """
uv run python -c "
from gapless_deribit_clickhouse.clickhouse.connection import get_client
from gapless_deribit_clickhouse import collect_trades
import logging
logging.basicConfig(level=logging.INFO)

client = get_client()
count = client.command('SELECT count() FROM deribit.options_trades')
print(f'Current data: {count:,} rows')

if count < 100:
    print('Insufficient data - auto-seeding with 1 day of trades...')
    df = collect_trades(
        currency='BTC',
        start_date='2024-12-01',
        end_date='2024-12-02',
        insert_to_db=True,
        resume=False
    )
    print(f'✓ Seeded {len(df):,} trades')
else:
    print('✓ Sufficient data exists')

print()
print('To run E2E tests: mise run test-e2e')
"
"""
# REMOVED: depends_post = ["test-e2e"] - caused circular dependency
# User should explicitly run test-e2e after this task completes

[tasks.measure-volume]
description = "Measure actual Deribit data volume for 1 day"
run = """
uv run python -c "
from gapless_deribit_clickhouse import collect_trades

print('Measuring real Deribit data volume (1 day)...')
df = collect_trades(
    currency='BTC',
    start_date='2024-12-01',
    end_date='2024-12-02',
    insert_to_db=False
)

rows = len(df)
bytes_raw = df.memory_usage(deep=True).sum()
print(f'Rows per day: {rows:,}')
print(f'Bytes per day (raw): {bytes_raw:,}')
print(f'Bytes per row: {bytes_raw // rows if rows else 0}')
print(f'Estimated monthly: {rows * 30:,} rows, {bytes_raw * 30 / 1e9:.2f} GB')
print(f'Estimated full backfill (84 months): {rows * 30 * 84:,} rows')
"
"""

[tasks.measure-baseline]
description = "Record baseline costs from billing APIs"
run = "uv run scripts/measure_baseline_costs.py"

[tasks.monitor-egress]
description = "Check egress costs against threshold"
run = "uv run scripts/monitor_egress.py"

# =============================================================================
# ClickHouse Server Management Tasks
# ADR: 2025-12-08-mise-pagination-validation
# =============================================================================

[tasks._ch-dirs]
description = "Create ClickHouse data directories"
hide = true
run = 'mkdir -p "$CLICKHOUSE_DATA_DIR" "$CLICKHOUSE_LOG_DIR"'

[tasks.ch-start]
description = "Start local ClickHouse server"
depends = ["_ch-dirs"]
run = """
if [ -f "$CLICKHOUSE_PID_FILE" ] && kill -0 $(cat "$CLICKHOUSE_PID_FILE") 2>/dev/null; then
  echo "✓ ClickHouse already running (PID $(cat $CLICKHOUSE_PID_FILE))"
else
  clickhouse server --daemon \
    --pid-file="$CLICKHOUSE_PID_FILE" \
    --path="$CLICKHOUSE_DATA_DIR" \
    -- --logger.log="$CLICKHOUSE_LOG_DIR/clickhouse-server.log" \
       --logger.errorlog="$CLICKHOUSE_LOG_DIR/clickhouse-server.err.log"
  sleep 2
  curl -s http://localhost:8123/ping && echo "✓ ClickHouse started"
fi
"""

[tasks.ch-stop]
description = "Stop local ClickHouse server"
run = """
if [ -f "$CLICKHOUSE_PID_FILE" ]; then
  kill $(cat "$CLICKHOUSE_PID_FILE") 2>/dev/null && echo "✓ ClickHouse stopped"
  rm -f "$CLICKHOUSE_PID_FILE"
else
  echo "ClickHouse not running"
fi
"""

[tasks.ch-status]
description = "Check ClickHouse server status"
run = 'curl -s http://localhost:8123/ping && echo "✓ ClickHouse running" || echo "❌ ClickHouse not running"'

[tasks.ch-logs]
description = "Tail ClickHouse server logs"
run = "tail -f $CLICKHOUSE_LOG_DIR/clickhouse-server.log"

# =============================================================================
# Quality Tasks
# ADR: 2025-12-08-mise-pagination-validation
# =============================================================================

[tasks.type-check]
description = "Run mypy type checking"
run = "uv run mypy src/"

[tasks.lint-all]
description = "Run all linting (ruff + mypy)"
depends = ["lint", "type-check"]
run = "echo '✓ All linting passed'"

[tasks.pre-release]
description = "Pre-release validation (lint + tests + security)"
depends = ["lint-all", "test-unit", "test-contracts", "security"]
run = "echo '✓ Ready for release'"

[tasks.dev]
description = "Start development environment"
depends = ["ch-start", "local-init"]
run = "echo '✓ Development environment ready'"

# =============================================================================
# DBeaver Configuration Tasks
# ADR: 2025-12-09-pydantic-dbeaver-config
# =============================================================================

[tasks.dbeaver-generate]
description = "Generate DBeaver config from Pydantic models"
run = "uv run scripts/generate_dbeaver_config.py"

[tasks.dbeaver-validate]
description = "Validate DBeaver config with Pydantic schema"
# ADR: 2025-12-09-pydantic-dbeaver-config
# Skill: clickhouse-pydantic-config (cc-skills)
run = "uv run scripts/validate_dbeaver_config.py"

[tasks.dbeaver]
description = "Launch DBeaver with project config (macOS)"
depends = ["dbeaver-generate", "dbeaver-validate"]
run = "/Applications/DBeaver.app/Contents/MacOS/dbeaver &"

[tasks.db-connect-info]
description = "Print connection settings for any GUI tool"
run = """
echo "=== ClickHouse Connection Settings ==="
echo ""
echo "LOCAL (development):"
echo "  Host:     localhost"
echo "  Port:     8123 (HTTP)"
echo "  Database: deribit"
echo "  User:     default"
echo "  Password: (empty)"
echo "  SSL:      No"
echo ""
echo "CLOUD (production):"
echo "  Host:     $CLICKHOUSE_HOST_READONLY"
echo "  Port:     443 (HTTPS)"
echo "  Database: deribit"
echo "  User:     $CLICKHOUSE_USER_READONLY"
echo "  Password: (from .env)"
echo "  SSL:      Yes"
"""

# =============================================================================
# Alpha Features Tasks
# ADR: 2025-12-10-deribit-options-alpha-features
# =============================================================================

[tasks.features-demo]
description = "Demo alpha features with sample data"
depends = ["_check-credentials", "_check-data-exists"]
run = """
uv run python -c "
from gapless_deribit_clickhouse.clickhouse.connection import get_client
from gapless_deribit_clickhouse.features import (
    resample_iv, iv_percentile, term_structure_slope, pcr_by_tenor, dte_bucket_agg
)
import pandas as pd

print('=== Alpha Features Demo ===')
print()

# Fetch sample data
client = get_client()
df = client.query_df('''
    SELECT timestamp, iv, amount, price, option_type,
           dateDiff(day, toDate(timestamp), expiry) as dte
    FROM deribit.options_trades
    WHERE iv IS NOT NULL
    ORDER BY timestamp DESC
    LIMIT 10000
''')

print(f'Loaded {len(df):,} trades')
print()

# 1. Resample IV
print('1. IV Resampling (15-min)...')
try:
    resampled = resample_iv(df)
    print(f'   Resampled to {len(resampled)} bars')
    print(f'   Columns: {list(resampled.columns)}')
except Exception as e:
    print(f'   Error: {e}')
print()

# 2. IV Percentile
print('2. IV Percentile (90-day)...')
try:
    if len(resampled) > 0:
        pct = iv_percentile(resampled['iv_close'], lookback_days=7)  # Use 7d for demo
        print(f'   Latest percentile: {pct.dropna().iloc[-1]:.1f}%')
except Exception as e:
    print(f'   Error: {e}')
print()

# 3. PCR by Tenor
print('3. Put-Call Ratio by Tenor...')
try:
    pcr = pcr_by_tenor(df)
    print(f'   Buckets: {list(pcr.columns)}')
    for col in pcr.columns[:3]:
        latest = pcr[col].dropna().iloc[-1] if not pcr[col].dropna().empty else float('nan')
        print(f'   {col}: {latest:.2f}')
except Exception as e:
    print(f'   Error: {e}')
print()

# 4. DTE Bucket Aggregations
print('4. DTE Bucket Aggregations...')
try:
    dte_agg = dte_bucket_agg(df)
    print(f'   Metrics: {len(dte_agg.columns)} columns')
    print(f'   Sample: {list(dte_agg.columns)[:5]}')
except Exception as e:
    print(f'   Error: {e}')
print()

print('=== Demo Complete ===')
"
"""

[tasks.features-test]
description = "Run feature module tests"
run = "uv run pytest tests/features/ -v"

[tasks.features-benchmark]
description = "Benchmark feature computation performance"
depends = ["_check-credentials", "_check-data-exists"]
run = """
uv run python -c "
import time
from gapless_deribit_clickhouse.clickhouse.connection import get_client
from gapless_deribit_clickhouse.features import resample_iv, iv_percentile

print('=== Feature Benchmark ===')

client = get_client()

# Fetch 100k trades
print('Fetching 100,000 trades...')
start = time.time()
df = client.query_df('''
    SELECT timestamp, iv, amount, price, option_type,
           dateDiff(day, toDate(timestamp), expiry) as dte
    FROM deribit.options_trades
    WHERE iv IS NOT NULL
    ORDER BY timestamp DESC
    LIMIT 100000
''')
fetch_time = time.time() - start
print(f'  Fetch time: {fetch_time:.2f}s')

# Benchmark resampling
print('Benchmarking resample_iv...')
start = time.time()
resampled = resample_iv(df)
resample_time = time.time() - start
print(f'  Resample time: {resample_time:.2f}s ({len(resampled)} bars)')

# Benchmark IV percentile
print('Benchmarking iv_percentile...')
start = time.time()
pct = iv_percentile(resampled['iv_close'], lookback_days=90)
percentile_time = time.time() - start
print(f'  Percentile time: {percentile_time:.2f}s')

print()
print('Summary:')
print(f'  Total: {fetch_time + resample_time + percentile_time:.2f}s')
"
"""
